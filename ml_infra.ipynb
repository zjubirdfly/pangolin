{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from scipy.fftpack import fft,ifft\n",
    "import matplotlib.pyplot as plt\n",
    "## Imports: Keras Models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Cropping2D\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "import siina\n",
    "\n",
    "richwater_path = \"/home/birdfly/Data/Radar/richwater/\"\n",
    "broken_path = \"/home/birdfly/Data/Radar/broken/\"\n",
    "empty_path = \"/home/birdfly/Data/Radar/empty/\"\n",
    "normal_path = \"/home/birdfly/Data/Radar/normal/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_time_to_freq(data, samplefrequency, freq_from, freq_to):\n",
    "    \"\"\" Transfer time series data to frequency data.\n",
    "    \n",
    "    Parameters:\n",
    "    data: DZT data N*M, where N is the number of channels and M is the number of times.\n",
    "    samplefrequency: sample frequency of DZT data. For example, 250.(Hz).\n",
    "    freq_from: Lower bound of frequency band width. For example, 0.\n",
    "    freq_to: Upper bound of frequency band width. For example, 50.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    freq_data: N*(freq_to-freq_from) matrix, where N is the number of channels.\n",
    "    \"\"\"\n",
    "    freq_data = []\n",
    "    for row_index in data:  \n",
    "        fft_y=fft(data[row_index])\n",
    "        T = 1/frequency \n",
    "        N = data[row_index].size\n",
    "        freq_data_row = np.abs(fft_y)[:N // 2] * 1 / N\n",
    "        freq_data.extend(freq_data_row[freq_from:freq_to])\n",
    "\n",
    "    return freq_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dzt_file(filepath):\n",
    "    \"\"\" Read DZT file from a given path.\n",
    "    \n",
    "    Parameter: \n",
    "    filepath: str\n",
    "    Path to a dzt-file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    header : dictionary\n",
    "        First header, length of 1024 bytes, unpacked.\n",
    "        Other headers are found as a list of bytes under 'other_headers'.\n",
    "    data : list of numpy arrays\n",
    "        Each channel in Fortran (column oriented) format.\n",
    "        In case of failing to reshape, returns one numpy array in a list.\n",
    "        Error message is found in the header-dict. \n",
    "    \"\"\"\n",
    "    meas = siina.Radar()\n",
    "    meas.read_file(filepath)\n",
    "\n",
    "    return meas.header, meas.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_directory(filepaths):\n",
    "    \"\"\" Read all the files in the given pathes.\n",
    "    \n",
    "    Parameter:\n",
    "    filepaths: a list of paths, where each path contains a category of files.\n",
    "        For ex, [richwater_path, broken_path]\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X_train: the training data set.\n",
    "    y_train: the label of training data set.\n",
    "    \"\"\"\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    category = 0\n",
    "    \n",
    "    for filepath in filepaths:\n",
    "        files = glob.glob(filepath + \"/*.DZT\")\n",
    "        for file in files:\n",
    "            print(file)\n",
    "            header, data = read_dzt_file(file) \n",
    "            X_train.append(data)\n",
    "            Y_train.append(category)       \n",
    "        category = category + 1\n",
    "            \n",
    "    X_train = np.asarray(X_train)\n",
    "    Y_train = tf.keras.utils.to_categorical(y=Y_train, num_classes=len(filepaths))\n",
    "    \n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(x_train, y_train, x_test, y_test):\n",
    "    model = tf.keras.models.Sequential([\n",
    "#         tf.keras.layers.Flatten(),\n",
    "#         tf.keras.layers.Dense((freq_to - freq_from)*channels_count, activation='relu'),\n",
    "#         tf.keras.layers.Dense(max(freq_to - freq_from,channels_count), activation='relu'), \n",
    "#         tf.keras.layers.Dense(min(freq_to - freq_from,channels_count), activation='relu'),     \n",
    "#         tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "#     model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "#     history = model.fit(x_train, y_train, epochs= 10)\n",
    "#     model.evaluate(x_test, y_test)\n",
    "#     # list all data in history\n",
    "#     print(history.history.keys())\n",
    "#     # summarize history for accuracy\n",
    "#     plt.plot(history.history['accuracy'])\n",
    "#     plt.title('model accuracy')\n",
    "#     plt.ylabel('accuracy')\n",
    "#     plt.xlabel('epoch')\n",
    "#     plt.legend(['train', 'test'], loc='upper left')\n",
    "#     plt.show()\n",
    "#     # summarize history for loss\n",
    "#     plt.plot(history.history['loss'])\n",
    "#     plt.title('model loss')\n",
    "#     plt.ylabel('loss')\n",
    "#     plt.xlabel('epoch')\n",
    "#     plt.legend(['train', 'test'], loc='upper left')\n",
    "#     plt.show()\n",
    "#     model.save('model.h5')\n",
    "#     print('model.h5 has been saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    x, y = read_directory([richwater_path, broken_path, empty_path,normal_path])\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    run_model(x_train, y_train, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
